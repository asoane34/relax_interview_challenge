{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engagement data schema\n",
    "● name: the user's name\n",
    "\n",
    "● object_id: the user's id\n",
    "\n",
    "● email: email address\n",
    "\n",
    "● creation_source: how their account was created. This takes on one\n",
    "of 5 values:\n",
    "    \n",
    "    ○ PERSONAL_PROJECTS: invited to join another user's personal workspace\n",
    "    \n",
    "    ○ GUEST_INVITE: invited to an organization as a guest (limited permissions)\n",
    "    \n",
    "    ○ ORG_INVITE: invited to an organization (as a full member)\n",
    "    \n",
    "    ○ SIGNUP: signed up via the website\n",
    "    \n",
    "    ○ SIGNUP_GOOGLE_AUTH: signed up using Google\n",
    "    Authentication (using a Google email account for their login\n",
    "     id)\n",
    "\n",
    "● creation_time: when they created their account\n",
    "\n",
    "● last_session_creation_time: unix timestamp of last login\n",
    "\n",
    "● opted_in_to_mailing_list: whether they have opted into receiving\n",
    "marketing emails\n",
    "\n",
    "● enabled_for_marketing_drip: whether they are on the regular\n",
    "marketing email drip\n",
    "\n",
    "● org_id: the organization (group of users) they belong to\n",
    "\n",
    "● invited_by_user_id: which user invited them to join (if applicable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target: \n",
    "## Adopted User:\n",
    "\n",
    "Has logged in to product on three separate days in at least one seven-day period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in relevant data\n",
    "users = pd.read_csv('./takehome_users.csv', encoding = 'latin1')\n",
    "engagement = pd.read_csv('./takehome_user_engagement.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in this process is to create the target feature. My methodology will be simple: Using the __engagement__ dataframe, I will create a Datetime Index using the time_stamp feature, downsample this Index to weekly observations and count the number unique user_id logins per week period, recording all unique user_ids that appear at least three times in one of the created week level bins. Then, with a set of user_ids that qualify as \"adopted users\", I will add a binary feature to the __users__ dataframe representing whether or not a given user qualifies as an \"adopted user\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>visited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-22 03:53:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-15 03:45:04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-11-29 03:45:04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-09 03:45:04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-25 03:45:04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_stamp  user_id  visited\n",
       "0  2014-04-22 03:53:30        1        1\n",
       "1  2013-11-15 03:45:04        2        1\n",
       "2  2013-11-29 03:45:04        2        1\n",
       "3  2013-12-09 03:45:04        2        1\n",
       "4  2013-12-25 03:45:04        2        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view datatable head\n",
    "engagement.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert time stamp to datetime object and set as a DateimeIndex\n",
    "engagement['time_stamp'] = pd.to_datetime(engagement['time_stamp'], format = '%Y-%m-%d %H:%M:%S')\n",
    "engagement = engagement.set_index(engagement.time_stamp).drop(columns = ['time_stamp'])\n",
    "\n",
    "#usage counts\n",
    "counts = engagement.resample('7D').user_id.value_counts()\n",
    "\n",
    "#extract multi users\n",
    "adopted_indices = counts[counts >= 3].index\n",
    "\n",
    "#create set of adopted user ids \n",
    "adopted = set()\n",
    "for index in adopted_indices:\n",
    "    adopted.add(index[1]) \n",
    "    \n",
    "#create target variable\n",
    "users['adopted_user'] = users.object_id.apply(lambda x: 1 if x in adopted else 0)\n",
    "#view information for dataframe \n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>creation_source</th>\n",
       "      <th>last_session_creation_time</th>\n",
       "      <th>opted_in_to_mailing_list</th>\n",
       "      <th>enabled_for_marketing_drip</th>\n",
       "      <th>org_id</th>\n",
       "      <th>invited_by_user_id</th>\n",
       "      <th>adopted_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-22 03:53:30</td>\n",
       "      <td>Clausen August</td>\n",
       "      <td>AugustCClausen@yahoo.com</td>\n",
       "      <td>GUEST_INVITE</td>\n",
       "      <td>1.398139e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10803.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-11-15 03:45:04</td>\n",
       "      <td>Poole Matthew</td>\n",
       "      <td>MatthewPoole@gustr.com</td>\n",
       "      <td>ORG_INVITE</td>\n",
       "      <td>1.396238e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-03-19 23:14:52</td>\n",
       "      <td>Bottrill Mitchell</td>\n",
       "      <td>MitchellBottrill@gustr.com</td>\n",
       "      <td>ORG_INVITE</td>\n",
       "      <td>1.363735e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-05-21 08:09:28</td>\n",
       "      <td>Clausen Nicklas</td>\n",
       "      <td>NicklasSClausen@yahoo.com</td>\n",
       "      <td>GUEST_INVITE</td>\n",
       "      <td>1.369210e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5151.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013-01-17 10:14:20</td>\n",
       "      <td>Raw Grace</td>\n",
       "      <td>GraceRaw@yahoo.com</td>\n",
       "      <td>GUEST_INVITE</td>\n",
       "      <td>1.358850e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>5240.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id        creation_time               name  \\\n",
       "0          1  2014-04-22 03:53:30     Clausen August   \n",
       "1          2  2013-11-15 03:45:04      Poole Matthew   \n",
       "2          3  2013-03-19 23:14:52  Bottrill Mitchell   \n",
       "3          4  2013-05-21 08:09:28    Clausen Nicklas   \n",
       "4          5  2013-01-17 10:14:20          Raw Grace   \n",
       "\n",
       "                        email creation_source  last_session_creation_time  \\\n",
       "0    AugustCClausen@yahoo.com    GUEST_INVITE                1.398139e+09   \n",
       "1      MatthewPoole@gustr.com      ORG_INVITE                1.396238e+09   \n",
       "2  MitchellBottrill@gustr.com      ORG_INVITE                1.363735e+09   \n",
       "3   NicklasSClausen@yahoo.com    GUEST_INVITE                1.369210e+09   \n",
       "4          GraceRaw@yahoo.com    GUEST_INVITE                1.358850e+09   \n",
       "\n",
       "   opted_in_to_mailing_list  enabled_for_marketing_drip  org_id  \\\n",
       "0                         1                           0      11   \n",
       "1                         0                           0       1   \n",
       "2                         0                           0      94   \n",
       "3                         0                           0       1   \n",
       "4                         0                           0     193   \n",
       "\n",
       "   invited_by_user_id  adopted_user  \n",
       "0             10803.0             0  \n",
       "1               316.0             0  \n",
       "2              1525.0             0  \n",
       "3              5151.0             0  \n",
       "4              5240.0             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data table head\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several features such as __object_id__, __name__, and __email__ that either hold no value in modelling or were only used as a merge key. These will be dropped. I will also convert __creation_source__, a categorical variable with five levels, to binary features via one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop merge keys and trivial object features\n",
    "users = users.drop(columns = ['object_id', 'name', 'email'])\n",
    "\n",
    "#create dummy variable from creation_source\n",
    "creation_source = pd.get_dummies(users.creation_source)\n",
    "#add back to main frame\n",
    "users = pd.concat([users, creation_source], axis = 1).drop(columns = ['creation_source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "On their own, __last_session_creation_time__ and __invited_by_user_id__ lack value to generating a model. However, these features can yield two potentially important features. The timedelta between account creation and the last session used could potentially be valuable, and whether or not the user who invited the user is an adopted user themselves could also be potentially valuable. The code below will extract these two features in a format that the model can make use of. There is also the question of what to do with __org_id__. Because __org_id__ is a categorical variable with hundreds of levels, it would be unwise to leave the feature as is (machine learning algorithms will interpret higher __ord_ids__ as \"larger\" values, which is obviously not correct in this case, they merely represent different organizations) but because there are so many levels, we are looking at creating hundreds of features. The solution to this will be to use convert create binary variables from __ord_ids__ and convert the dataframe to a sparse matrix to conserve memory. Likely most of these will not end up being important to modelling, and thus using an algorithm down the road that penalizes and removes unimportant features (e.g., Lasso or anything else with L1 regularization) will help in removing unimportant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Timedelta feature to analyze minimum early activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#quick check on null value login times\n",
    "check_nulls = users[(users.last_session_creation_time.isnull()) & (users.adopted_user == 1)]\n",
    "print(len(check_nulls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran the block of code above to check if there were any users who had null values for __last_session_creation_time__ but were classified as __adopted_users__. The reason being, in creating features for minimum user activity, I needed to ensure my assumption that a null value in __last_session_creation_time__ means that the user never logged in, meaning I can fill null values with a timedelta of $0$. While this is not a perfect test, it was a quick data verification check before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9437 users did not login after their first week\n",
      "\n",
      "10082 users did not login after their first month\n"
     ]
    }
   ],
   "source": [
    "#transform date features into usable datetime objects\n",
    "users['creation_time'] = pd.to_datetime(users['creation_time'], format = '%Y-%m-%d %H:%M:%S')\n",
    "users['last_session_creation_time'] = pd.to_datetime(users['last_session_creation_time'], unit = 's')\n",
    "\n",
    "#get times difference between last login and first login\n",
    "users['timedeltas'] = users.last_session_creation_time - users.creation_time\n",
    "\n",
    "#fill null values (assuming zero logins)\n",
    "zero_logins = pd.Timedelta(0, unit = 's')\n",
    "users['timedeltas'] = users.timedeltas.fillna(zero_logins)\n",
    "\n",
    "#create timedelta objects for 1 week and 1 month\n",
    "week = pd.Timedelta(7, unit = 'D')\n",
    "month = pd.Timedelta(30, unit = 'D')\n",
    "\n",
    "print('{} users did not login after their first week'.format(len(users.timedeltas[users.timedeltas < week])))\n",
    "print()\n",
    "print('{} users did not login after their first month'.format(len(users.timedeltas[users.timedeltas < month])))\n",
    "\n",
    "#create feature: users still active for 1 week, still active after 1 month \n",
    "users['min_1week'] = users.timedeltas.apply(lambda x: 1 if x > week  else 0)\n",
    "users['min_1month'] = users.timedeltas.apply(lambda x: 1 if x > month  else 0)\n",
    "users = users.drop(columns = ['last_session_creation_time', 'creation_time', 'timedeltas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating invited by adopted user feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "users['invited_by_adopted'] = users.invited_by_user_id.apply(lambda x: 1 if x in adopted else 0)\n",
    "users = users.drop(columns = ['invited_by_user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with org_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 417 different levels of \"org_id\"\n"
     ]
    }
   ],
   "source": [
    "#check number of levels\n",
    "print('There are {} different levels of \"org_id\"'.format(len(users.org_id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dummy variables \n",
    "orgs = pd.get_dummies(users.org_id)\n",
    "\n",
    "#concatentate to main frame and drop original column\n",
    "users = pd.concat([users, orgs], axis = 1).drop(columns = ['org_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract target feature\n",
    "target = users.adopted_user\n",
    "\n",
    "#create sparse feature matrix\n",
    "users = users.drop(columns = ['adopted_user'])\n",
    "feature_cols = list(users.columns)\n",
    "X = csr_matrix(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "I will begin with a simple Logistic Regression with an L1 regularization. I have selected L1 regularization here because the matrix is sparse and L1 regularization has a strong penalty for unimportant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the baseline linear model was 0.9455555555555556\n",
      "\n",
      "The area under the ROC curve for the baseline linear model was 0.944126984126984\n"
     ]
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, target, test_size = 0.3, random_state = 43)\n",
    "lr = LogisticRegression(penalty = 'l1', solver = 'liblinear', max_iter = 1000)\n",
    "lr.fit(xtrain, ytrain)\n",
    "ypreds = lr.predict(xtest)\n",
    "print('The accuracy of the baseline linear model was {}'.format(accuracy_score(ytest, ypreds)))\n",
    "print()\n",
    "print('The area under the ROC curve for the baseline linear model was {}'.format(roc_auc_score(ytest, ypreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look into feature importances for baseline model \n",
    "coefficients = lr.coef_[0]\n",
    "log_feature_importances = pd.DataFrame({'feature' : feature_cols, 'importance' : coefficients})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>min_1week</td>\n",
       "      <td>4.538556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>min_1month</td>\n",
       "      <td>4.242808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>118</td>\n",
       "      <td>1.114544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>339</td>\n",
       "      <td>1.078317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>341</td>\n",
       "      <td>0.811375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>131</td>\n",
       "      <td>0.710513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>82</td>\n",
       "      <td>0.630841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>0.456881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>219</td>\n",
       "      <td>0.429600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>89</td>\n",
       "      <td>0.404141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>invited_by_adopted</td>\n",
       "      <td>0.384525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>0.339753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64</td>\n",
       "      <td>0.337493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>343</td>\n",
       "      <td>0.288626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>117</td>\n",
       "      <td>0.233071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>366</td>\n",
       "      <td>0.223512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>46</td>\n",
       "      <td>0.175722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>0.154704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opted_in_to_mailing_list</td>\n",
       "      <td>0.127696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>306</td>\n",
       "      <td>0.118433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature  importance\n",
       "6                  min_1week    4.538556\n",
       "7                 min_1month    4.242808\n",
       "36                       118    1.114544\n",
       "62                       339    1.078317\n",
       "64                       341    0.811375\n",
       "41                       131    0.710513\n",
       "27                        82    0.630841\n",
       "13                         7    0.456881\n",
       "52                       219    0.429600\n",
       "29                        89    0.404141\n",
       "8         invited_by_adopted    0.384525\n",
       "11                         3    0.339753\n",
       "25                        64    0.337493\n",
       "65                       343    0.288626\n",
       "35                       117    0.233071\n",
       "68                       366    0.223512\n",
       "20                        46    0.175722\n",
       "15                        13    0.154704\n",
       "0   opted_in_to_mailing_list    0.127696\n",
       "59                       306    0.118433"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_feature_importances = log_feature_importances[log_feature_importances.importance != 0].reset_index(drop = True).\\\n",
    "sort_values(by = ['importance'], ascending = False)\n",
    "log_feature_importances.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on single feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create single feature to test on\n",
    "min1_week = users.min_1week\n",
    "min1_week = np.array(min1_week).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the baseline linear model was 0.9044444444444445\n",
      "\n",
      "The area under the ROC curve for the baseline linear model was 0.9434920634920635\n"
     ]
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(min1_week, target, test_size = 0.3, random_state = 43)\n",
    "lr = LogisticRegression(penalty = 'l1', solver = 'liblinear', max_iter = 1000)\n",
    "lr.fit(xtrain, ytrain)\n",
    "ypreds = lr.predict(xtest)\n",
    "print('The accuracy of the baseline linear model was {}'.format(accuracy_score(ytest, ypreds)))\n",
    "print()\n",
    "print('The area under the ROC curve for the baseline linear model was {}'.format(roc_auc_score(ytest, ypreds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Removing Primary Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the baseline linear model was 0.8738888888888889\n",
      "\n",
      "The area under the ROC curve for the baseline linear model was 0.49936507936507935\n"
     ]
    }
   ],
   "source": [
    "new = users.drop(columns = ['min_1week', 'min_1month'])\n",
    "X2 = csr_matrix(new)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X2, target, test_size = 0.3, random_state = 43)\n",
    "lr = LogisticRegression(penalty = 'l1', solver = 'liblinear', max_iter = 1000)\n",
    "lr.fit(xtrain, ytrain)\n",
    "ypreds = lr.predict(xtest)\n",
    "print('The accuracy of the baseline linear model was {}'.format(accuracy_score(ytest, ypreds)))\n",
    "print()\n",
    "print('The area under the ROC curve for the baseline linear model was {}'.format(roc_auc_score(ytest, ypreds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An area under the ROC curve of nearly $0.5$ indicates that there is no decision boundary in this data, rather there is heavy class imbalance and the model is just predicting the more common value. If we look at the distribution of the predicted values versus the actual distribution of the test set, we will see this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3596\n",
       "1       4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check predicted values distribution\n",
    "series = pd.Series(ypreds)\n",
    "series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3150\n",
       "1     450\n",
       "Name: adopted_user, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_series = pd.Series(ytest)\n",
    "true_series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Far and away the most important indicator of whether or not someone will become an adopted user is whether they continue to use the product after the first week. That single feature alone explains $94\\%$ of the variance in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
